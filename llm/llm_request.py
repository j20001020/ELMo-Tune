import os
import re
from google import genai
from google.genai import types

GEMINI_MODEL = "gemini-2.5-flash"

# Environment variables
api_key = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=api_key)

def request_llm(system_content, user_contents, temperature):
    '''
    Function to make an API call to GEMINI

    Parameters:
    - system_content: string containing the system information
    - chunk_string: string containing the chunk of the options file
    - previous_option_files: list of tuples containing the previous option files and their benchmark results
    - temperature: Float (0-1) controlling GPT-4's output randomness.
    - average_cpu_used: Float indicating average CPU usage (default -1.0).
    - average_mem_used: Float indicating average memory usage (default -1.0).
    - test_name: String stating the benchmark test.

    Returns:
    - matches: string containing the options file generated by GPT-4
    '''
    messages = []
    for content in user_contents:
        messages.append(content)


    # Assuming 'client' is already defined and authenticated for GEMINI API access
    completion = client.models.generate_content(
        model=GEMINI_MODEL,
        config=types.GenerateContentConfig(
            system_instruction=system_content,
            temperature=temperature,
            max_output_tokens=4096,
            frequency_penalty=0,
            presence_penalty=0,
            thinking_config=types.ThinkingConfig(thinking_budget=0)
        ),
        contents=messages,
    )

    # Extract the assistant's reply
    assistant_reply = completion.text
    matches = re.match("[\s\S]*```([\s\S]*)```([\s\S]*)", assistant_reply)

    # Check if result is good
    if matches is not None:
        return matches 

    # Invalid response
    with open("invalid_assistant_reply.txt", "a") as file:
        file.write(assistant_reply + "\n\n" + "-" * 150 + "\n\n")
    return None
